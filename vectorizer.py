import re
import pefile
import hashlib
import numpy as np
from sklearn.feature_extraction import FeatureHasher

class FeatureType(object):
    ''' Base class from which each feature type may inherit '''
    name = ''
    dim = 0

    def __repr__(self):
        return '{}({})'.format(self.name, self.dim)

    def raw_features(self, bytez, pe):
        ''' Generate a JSON-able representation of the file '''
        raise (NotImplementedError)

    def process_raw_features(self, raw_obj):
        ''' Generate a feature vector from the raw features '''
        raise (NotImplementedError)

    def feature_vector(self, bytez, lief_binary):
        ''' Directly calculate the feature vector from the sample itself. This should only be implemented differently
        if there are significant speedups to be gained from combining the two functions. '''
        return self.process_raw_features(self.raw_features(bytez, lief_binary))


class SectionInfo(FeatureType):
    ''' Information about section names, sizes and entropy.  Uses hashing trick
    to summarize all this section info into a feature vector.
    '''

    name = 'section'
    dim = 5 + 50 + 50 + 50 + 50 + 50

    def __init__(self):
        super(FeatureType, self).__init__()

    @staticmethod
    def _properties(s):
        return [str(c).split('.')[-1] for c in s.characteristics_lists]

    def raw_features(self, bytez, pe):
        if pe is None:
            return {"entry": "", "sections": []}

        # properties of entry point, or if invalid, the first executable section
        # try:
        # except lief.not_found:
        #     # bad entry point, let's find the first executable section
        #     entry_section = ""
        #     for s in pe.sections:
        #         if lief.PE.SECTION_CHARACTERISTICS.MEM_EXECUTE in s.characteristics_lists:
        #             entry_section = s.name
        #             break

        entry_section = pe.get_section_by_rva(pe.OPTIONAL_HEADER.AddressOfEntryPoint).name
        raw_obj = {"entry": entry_section}
        raw_obj["sections"] = [{
            'name': s.Name,
            'size': s.SizeOfRawData,
            'entropy': s.get_entropy(),
            'vsize': s.Misc_VirtualSize,
            # 'props': self._properties(s)
        } for s in pe.sections]

        return raw_obj



    def process_raw_features(self, raw_obj):

        sections = raw_obj['sections']
        general = [
            len(sections),  # total number of sections
            # number of sections with nonzero size
            sum(1 for s in sections if s['size'] == 0),
            # number of sections with an empty name
            sum(1 for s in sections if s['name'] == ""),
            # number of RX
            sum(1 for s in sections if 'MEM_READ' in s['props'] and 'MEM_EXECUTE' in s['props']),
            # number of W
            sum(1 for s in sections if 'MEM_WRITE' in s['props'])
        ]

        # gross characteristics of each section
        section_sizes = [(s['name'], s['size']) for s in sections]
        section_sizes_hashed = FeatureHasher(50, input_type="pair").transform([section_sizes]).toarray()[0]
        section_entropy = [(s['name'], s['entropy']) for s in sections]
        section_entropy_hashed = FeatureHasher(50, input_type="pair").transform([section_entropy]).toarray()[0]
        section_vsize = [(s['name'], s['vsize']) for s in sections]
        section_vsize_hashed = FeatureHasher(50, input_type="pair").transform([section_vsize]).toarray()[0]
        entry_name_hashed = FeatureHasher(50, input_type="string").transform([raw_obj['entry']]).toarray()[0]
        characteristics = [p for s in sections for p in s['props'] if s['name'] == raw_obj['entry']]
        characteristics_hashed = FeatureHasher(50, input_type="string").transform([characteristics]).toarray()[0]

        return np.hstack([

            general, section_sizes_hashed, section_entropy_hashed, section_vsize_hashed, entry_name_hashed,

            characteristics_hashed

        ]).astype(np.float32)

class PEFeatureExtractor(object):
    ''' Extract useful features from a PE file, and return as a vector of fixed size. '''

    def __init__(self):
        self.features = [
            # ByteHistogram(),
            # ByteEntropyHistogram(),
            # StringExtractor(),
            # GeneralFileInfo(),
            # HeaderFileInfo(),
            SectionInfo(),
            # ImportsInfo(),
            # ExportsInfo()
        ]

        self.dim = sum([fe.dim for fe in self.features])

    def raw_features(self, bytez):
        # #lief_errors = (lief.bad_format, lief.bad_file, lief.pe_error, lief.parser_error, lief.read_out_of_bound,
        #                RuntimeError)

        try:
            lief_binary = lief.PE.parse(list(bytez))

        except lief_errors as e:
            print("lief error: ", str(e))
            lief_binary = None

        except Exception:  # everything else (KeyboardInterrupt, SystemExit, ValueError):
            raise

        features = {"sha256": hashlib.sha256(bytez).hexdigest()}
        features.update({fe.name: fe.raw_features(bytez, lief_binary) for fe in self.features})
        return features

    def process_raw_features(self, raw_obj):
        feature_vectors = [fe.process_raw_features(raw_obj[fe.name]) for fe in self.features]
        return np.hstack(feature_vectors).astype(np.float32)

    def feature_vector(self, bytez):
        return self.process_raw_features(self.raw_features(bytez))

    class DataDirectories(FeatureType):
        ''' Extracts size and virtual address of the first 15 data directories '''

        name = 'datadirectories'
        dim = 15 * 2

        def __init__(self):
            super(FeatureType, self).__init__()
            self._name_order = [
                "EXPORT_TABLE", "IMPORT_TABLE", "RESOURCE_TABLE", "EXCEPTION_TABLE", "CERTIFICATE_TABLE",
                "BASE_RELOCATION_TABLE", "DEBUG", "ARCHITECTURE", "GLOBAL_PTR", "TLS_TABLE", "LOAD_CONFIG_TABLE",
                "BOUND_IMPORT", "IAT", "DELAY_IMPORT_DESCRIPTOR", "CLR_RUNTIME_HEADER"
            ]

        def raw_features(self, bytez, pe):
            output = []
            if pe is None:
                return output

            for data_directory in pe.OPTIONAL_HEADER.DATA_DIRECTORY:
                output.append({
                    "name": str(data_directory.type).replace("DIRECTORY_ENTRY", ""),
                    "size": data_directory.size,
                    "virtual_address": data_directory.rva
                })
            return output

        def process_raw_features(self, raw_obj):
            features = np.zeros(2 * len(self._name_order), dtype=np.float32)
            for i in range(len(self._name_order)):
                if i < len(raw_obj):
                    features[2 * i] = raw_obj[i]["size"]
                    features[2 * i + 1] = raw_obj[i]["virtual_address"]
            return features

